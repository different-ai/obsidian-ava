{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import datetime\n",
    "import obsidiantools.api as otools\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkd = Path(os.getcwd()).parent.parent.parent\n",
    "vault = otools.Vault(wkd).connect().gather()\n",
    "\n",
    "corpus = []\n",
    "for k, v in vault.readable_text_index.items():\n",
    "    corpus.append(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file_name = f\"./fine_tune_{datetime.date.today().strftime('%d_%m_%Y')}.jsonl\"\n",
    "\n",
    "for e in corpus:\n",
    "    with open(out_file_name, \"a+\") as outfile:\n",
    "        json.dump({\n",
    "            \"prompt\": f\"\",\n",
    "            \"completion\": f\" {e} END\",\n",
    "        }, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n3 $out_file_name | jq ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute: openai tools fine_tunes.prepare_data -f /Users/louisbeaumont/Documents/brain/.obsidian/plugins/obsidian-ava/./fine_tune_17_09_2022.jsonl\n"
     ]
    }
   ],
   "source": [
    "!echo \"execute: openai tools fine_tunes.prepare_data -f $(pwd)/$out_file_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "train, test = train_test_split(\n",
    "    open(f\"{out_file_name.replace('.jsonl', '_prepared.jsonl')}\").read().splitlines(), test_size=0.1)\n",
    "with open(f\"{out_file_name.replace('.jsonl', '')}_prepared_train.jsonl\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(train))\n",
    "with open(f\"{out_file_name.replace('.jsonl', '')}_prepared_test.jsonl\", \"w\") as outfile:\n",
    "    outfile.write(\"\\n\".join(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n3 {out_file_name.replace('.jsonl', '')}_prepared_train.jsonl | jq ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/louisbeaumont/.netrc\n"
     ]
    }
   ],
   "source": [
    "from openai.wandb_logger import WandbLogger\n",
    "import wandb\n",
    "import re\n",
    "values = open(\".env\", \"r\").read()\n",
    "wandb_key = re.findall(r\"WANDB_KEY=\\\"(.*)\\\"\", values)[0]\n",
    "wandb.login(key=wandb_key, relogin=True)\n",
    "openai.api_key = re.findall(r\"OPENAI_API_KEY=\\\"(.*)\\\"\", values)[0]\n",
    "openai.organization = re.findall(r\"OPENAI_ORGANIZATION=\\\"(.*)\\\"\", values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = openai.File.create(\n",
    "  file=open(f\"{out_file_name.replace('.jsonl', '')}_prepared_train.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "valid_file = openai.File.create(\n",
    "  file=open(f\"{out_file_name.replace('.jsonl', '')}_prepared_test.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "ft = openai.FineTune.create(\n",
    "    training_file=train_file[\"id\"],\n",
    "    validation_file=valid_file[\"id\"],\n",
    "    model=\"curie\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlouis030195\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/louisbeaumont/Documents/brain/.obsidian/plugins/obsidian-ava/wandb/run-20220917_095423-ft-IiBkZ3nxfs1VyvkXIumXciC9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/louis030195/obsidian-openai/runs/ft-IiBkZ3nxfs1VyvkXIumXciC9\" target=\"_blank\">ft-IiBkZ3nxfs1VyvkXIumXciC9</a></strong> to <a href=\"https://wandb.ai/louis030195/obsidian-openai\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type str that is 209420 bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>elapsed_examples</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>elapsed_tokens</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>training_loss</td><td>▅▄▆▆▅▅▄▇▅▄▄▄▅▆▆▅▆▄▆█▆▅▆▄▆█▄▅▃▄▄▅▁▃▄▂▄▄▂▁</td></tr><tr><td>training_sequence_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_token_accuracy</td><td>▄▄▄▂▄▅▂▁▃▅▅▅▄▂▂▃▃▃▄▂▄▅▄▄▄▂▃▂▄▆▅▄█▆▃▆▄▄▆█</td></tr><tr><td>validation_loss</td><td>▆▆▄▃▆▆▆▆▃▃▅▄▆▄▁▃▄▅▅▄▄▆▅▆▄▃▇▆▄▄▆▃▄▄▄▄▅▄█▅</td></tr><tr><td>validation_sequence_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_token_accuracy</td><td>▁▃▃▂▁▃▃▂▆▆▃▂▂▂█▄▂▂▁▃▃▃▂▄▂▄▂▂▄▃▂▅▅▃▃▅▃▃▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>elapsed_examples</td><td>6664.0</td></tr><tr><td>elapsed_tokens</td><td>1966264.0</td></tr><tr><td>fine_tuned_model</td><td>curie:ft-personal-20...</td></tr><tr><td>status</td><td>succeeded</td></tr><tr><td>training_loss</td><td>1.28242</td></tr><tr><td>training_sequence_accuracy</td><td>0.0</td></tr><tr><td>training_token_accuracy</td><td>0.52262</td></tr><tr><td>validation_loss</td><td>1.87266</td></tr><tr><td>validation_sequence_accuracy</td><td>0.0</td></tr><tr><td>validation_token_accuracy</td><td>0.56171</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ft-IiBkZ3nxfs1VyvkXIumXciC9</strong>: <a href=\"https://wandb.ai/louis030195/obsidian-openai/runs/ft-IiBkZ3nxfs1VyvkXIumXciC9\" target=\"_blank\">https://wandb.ai/louis030195/obsidian-openai/runs/ft-IiBkZ3nxfs1VyvkXIumXciC9</a><br/>Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220917_095423-ft-IiBkZ3nxfs1VyvkXIumXciC9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'🎉 wandb sync completed successfully'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WandbLogger.sync(\n",
    "    id=ft[\"id\"],\n",
    "    project=\"obsidian-openai\",\n",
    "    tags=[\"generation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import openai\n",
    "import datetime\n",
    "values = open(\".env\", \"r\").read()\n",
    "openai.api_key = re.findall(r\"OPENAI_API_KEY=\\\"(.*)\\\"\", values)[0]\n",
    "openai.organization = re.findall(r\"OPENAI_ORGANIZATION=\\\"(.*)\\\"\", values)[0]\n",
    "model = \"curie:ft-personal-2022-09-17-07-49-44\"\n",
    "outputs = []\n",
    "async def comp():\n",
    "    response = openai.Completion.create(\n",
    "      model=model,\n",
    "      prompt=\"\",\n",
    "      temperature=0.7,\n",
    "      max_tokens=256,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "      stop=[\"END\"]\n",
    "    )\n",
    "    outputs.append(response[\"choices\"][0][\"text\"])\n",
    "import asyncio\n",
    "# generate 100 samples into a file\n",
    "await asyncio.gather(*[comp() for _ in range(10)])\n",
    "  \n",
    "with open(f\"./{model}_{datetime.date.today().strftime('%d_%m_%Y')}.jsonl\", \"w\") as outfile:\n",
    "  outfile.write((\"\\n\"+(\"-\"*5)+\"\\n\").join(outputs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eddc71dd976ac4021c418a83513af4a3a9e8a87c5733f71deeaeb6a27b82de3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
